{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNW8OTkN8NGRZcL6LmReTF7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/datascientist-ld1981/Speech-Recognition/blob/main/Language_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxt-UJA6L7li",
        "outputId": "9cf49ade-0241-4423-bab6-2f6d1b87d01c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next word (HMM): quickly\n"
          ]
        }
      ],
      "source": [
        "#Hidden Markov Model\n",
        "import numpy as np\n",
        "\n",
        "# Define transition probabilities (POS Tags: Noun, Verb, Adverb)\n",
        "transition_probs = {\n",
        "    'Noun': {'Verb': 0.6, 'Noun': 0.1, 'Adverb': 0.3},\n",
        "    'Verb': {'Noun': 0.5, 'Adverb': 0.4, 'Verb': 0.1},\n",
        "    'Adverb': {'Noun': 0.7, 'Verb': 0.2, 'Adverb': 0.1}\n",
        "}\n",
        "\n",
        "# Define emission probabilities (Words)\n",
        "emission_probs = {\n",
        "    'Noun': {'cat': 0.8, 'dog': 0.2},\n",
        "    'Verb': {'ran': 0.9, 'walked': 0.1},\n",
        "    'Adverb': {'quickly': 0.7, 'slowly': 0.3}\n",
        "}\n",
        "\n",
        "# Initial probabilities\n",
        "initial_probs = {'Noun': 0.5, 'Verb': 0.4, 'Adverb': 0.1}\n",
        "\n",
        "# Given sentence: \"The cat ran ___\"\n",
        "possible_next_words = ['quickly', 'slowly']\n",
        "\n",
        "# Compute probability for each next word\n",
        "predictions = {}\n",
        "for word in possible_next_words:\n",
        "    max_prob = 0\n",
        "    for pos in ['Noun', 'Verb', 'Adverb']:\n",
        "        prob = transition_probs['Verb'][pos] * emission_probs[pos].get(word, 0)\n",
        "        max_prob = max(max_prob, prob)\n",
        "    predictions[word] = max_prob\n",
        "\n",
        "# Predict the most likely next word\n",
        "predicted_word = max(predictions, key=predictions.get)\n",
        "print(f\"Predicted next word (HMM): {predicted_word}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ni gram model\n",
        "from collections import defaultdict\n",
        "\n",
        "# Sample corpus\n",
        "corpus = [\n",
        "    \"The cat ran quickly\",\n",
        "    \"The cat ran away\",\n",
        "    \"The dog ran fast\",\n",
        "    \"The cat walked slowly\"\n",
        "]\n",
        "\n",
        "# Build 2-gram model\n",
        "ngram_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "for sentence in corpus:\n",
        "    words = sentence.lower().split()\n",
        "    for i in range(len(words) - 1):\n",
        "        ngram_counts[words[i]][words[i + 1]] += 1\n",
        "\n",
        "# Compute probabilities\n",
        "def next_word_prediction(word):\n",
        "    next_word_probs = ngram_counts[word]\n",
        "    total = sum(next_word_probs.values())\n",
        "    probabilities = {w: count / total for w, count in next_word_probs.items()}\n",
        "    return max(probabilities, key=probabilities.get) if probabilities else None\n",
        "\n",
        "# Predict next word for \"The cat ran ___\"\n",
        "predicted_ngram_word = next_word_prediction(\"ran\")\n",
        "print(f\"Predicted next word (N-Gram): {predicted_ngram_word}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNyepjeYMZDR",
        "outputId": "ff2d8749-db0a-4758-8a21-848f428e47cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next word (N-Gram): quickly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade --force-reinstall gensim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9anucAwPgUC",
        "outputId": "7826181b-dbaf-4827-fca7-01fe2297d340"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting smart-open>=1.8.1 (from gensim)\n",
            "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.1.0\n",
            "    Uninstalling smart-open-7.1.0:\n",
            "      Successfully uninstalled smart-open-7.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.3\n",
            "    Uninstalling gensim-4.3.3:\n",
            "      Successfully uninstalled gensim-4.3.3\n",
            "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gensim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv2POx4ZOhZc",
        "outputId": "2dc78c0a-5c17-464c-b00d-af6238f9a231"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall numpy -y\n",
        "!pip install numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAF5tCrIPJ0a",
        "outputId": "cf4b1ad5-d921-4dd7-b295-576ada925682"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy==1.26.4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M7HNqfSPeKx",
        "outputId": "cbb8e88d-54f0-478b-b18a-7895a059268d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.4\n",
            "    Uninstalling numpy-2.2.4:\n",
            "      Successfully uninstalled numpy-2.2.4\n",
            "Successfully installed numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Sample corpus\n",
        "sentences = [\n",
        "    [\"the\", \"cat\", \"ran\", \"quickly\"],\n",
        "    [\"the\", \"dog\", \"ran\", \"fast\"],\n",
        "    [\"the\", \"boy\", \"walked\", \"slowly\"],\n",
        "    [\"the\", \"cat\", \"jumped\", \"away\"]\n",
        "]\n",
        "\n",
        "# Train Word2Vec model\n",
        "model = Word2Vec(sentences, vector_size=10, window=2, min_count=1, workers=4)\n",
        "\n",
        "# Get most similar word to \"ran\"\n",
        "predicted_word2vec = model.wv.most_similar(\"ran\", topn=1)[0][0]\n",
        "print(f\"Predicted next word (Word2Vec): {predicted_word2vec}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VucQ-9ryM1Dg",
        "outputId": "5eb6457b-b9f6-440f-e8eb-1b185e1e3760"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next word (Word2Vec): the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#AFTER REMOVING STOP WORDS\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "# Sample corpus (expanded for better learning)\n",
        "sentences = [\n",
        "    [\"the\", \"cat\", \"ran\", \"quickly\"],\n",
        "    [\"the\", \"dog\", \"ran\", \"fast\"],\n",
        "    [\"the\", \"boy\", \"walked\", \"slowly\"],\n",
        "    [\"the\", \"cat\", \"jumped\", \"away\"],\n",
        "    [\"she\", \"ran\", \"to\", \"store\"],\n",
        "    [\"runner\", \"moved\", \"quickly\"],\n",
        "    [\"they\", \"ran\", \"together\"]\n",
        "]\n",
        "\n",
        "# Remove stopwords (like \"the\")\n",
        "stopwords = {\"the\", \"to\", \"a\", \"an\"}  # Define common stopwords\n",
        "filtered_sentences = [[word for word in sentence if word not in stopwords] for sentence in sentences]\n",
        "\n",
        "# Train Word2Vec model\n",
        "model = Word2Vec(filtered_sentences, vector_size=50, window=3, min_count=1, workers=4)\n",
        "\n",
        "# Get most similar word to \"ran\"\n",
        "predicted_word2vec = model.wv.most_similar(\"ran\", topn=1)[0][0]\n",
        "print(f\"Predicted next word (Word2Vec): {predicted_word2vec}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHaHbqRZOd1y",
        "outputId": "d728f904-cdb1-4929-b825-911d20cf38bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next word (Word2Vec): fast\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-iaiSa5gQ2RC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}